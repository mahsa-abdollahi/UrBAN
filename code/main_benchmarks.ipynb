{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3b2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from time import gmtime\n",
    "from time import strftime\n",
    "from pathlib import Path\n",
    "from datetime import timedelta  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_extraction import feature_extraction, extract_statistic\n",
    "from sklearn.model_selection import LeaveOneGroupOut, KFold, GridSearchCV, PredefinedSplit, GroupKFold\n",
    "\n",
    "from regression_analysis import random_split_evaluation, independent_split_evaluation, random_baseline_metrics\n",
    "from regression_analysis import evaluate_model_performance, create_random_feature, clip_based_on_boxes\n",
    "from regression_analysis import get_errors_random, get_errors_independent, plot_erros \n",
    "from regression_analysis import random_split_ranking, independent_split_ranking, plot_top_features, plot_top_features_separate\n",
    "\n",
    "from regression_analysis import ml_gridsearchcv_kfold, random_split_cv, hive_independent_cv, features_selection_cv, balance_training_data, read_and_plot_results\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.fftpack\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb52ae5",
   "metadata": {},
   "source": [
    "# Labels 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e627b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109 entries, 0 to 108\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Date             109 non-null    object \n",
      " 1   Tag number       109 non-null    int64  \n",
      " 2   Colony Size      109 non-null    int64  \n",
      " 3   Fob 1st          109 non-null    float64\n",
      " 4   Fob 2nd          102 non-null    float64\n",
      " 5   Fob 3rd          31 non-null     float64\n",
      " 6   FoBrood          11 non-null     float64\n",
      " 7   Queen status     108 non-null    object \n",
      " 8   Frames of Honey  63 non-null     float64\n",
      " 9   Open             107 non-null    object \n",
      " 10  Close            107 non-null    object \n",
      " 11  Notes            64 non-null     object \n",
      "dtypes: float64(5), int64(2), object(5)\n",
      "memory usage: 10.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/annotations/inspections_2021.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e84df7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3629,    6, 3631, 3693, 3690, 3691, 3628, 3627, 3692, 3640])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(0)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "unique_hives = data['Tag number'].unique()\n",
    "unique_hives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a04b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby(['Tag number'])\n",
    "dict_hives = {}\n",
    "for i in unique_hives:\n",
    "        dict_hives[i] = grouped.get_group(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c148d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in  data['Tag number'].unique():\n",
    "    dict_hives[hive] = dict_hives[hive].set_index(dict_hives[hive]['Date'])\n",
    "    idx = pd.date_range(dict_hives[hive].index.min(), dict_hives[hive].index.max()+ timedelta(days=1), freq=\"15min\")#  + timedelta(days=12)\n",
    "    dict_hives[hive] = dict_hives[hive].reindex(idx)\n",
    "    dict_hives[hive] = dict_hives[hive].drop(['Date'], axis=1)\n",
    "    dict_hives[hive] = dict_hives[hive].interpolate(method=\"linear\")#interpolate(method=\"ffill\")\n",
    "    dict_hives[hive][\"fob\"] = dict_hives[hive][\"Fob 1st\"] + dict_hives[hive][\"Fob 2nd\"]+ dict_hives[hive][\"Fob 3rd\"]\n",
    "    dict_hives[hive][\"fob\"] = dict_hives[hive][\"fob\"]#.round(0).astype('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4f98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c68ba5",
   "metadata": {},
   "source": [
    "# Labels 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19930037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278 entries, 0 to 277\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Date           278 non-null    object\n",
      " 1   Tag number     278 non-null    int64 \n",
      " 2   Category       274 non-null    object\n",
      " 3   Action detail  274 non-null    object\n",
      " 4   Queen status   269 non-null    object\n",
      " 5   Is alive       278 non-null    int64 \n",
      " 6   Report notes   175 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 15.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_2022 = pd.read_csv(\"../data/annotations/inspections_2022.csv\")\n",
    "data_2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de90968f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag number</th>\n",
       "      <th>Category</th>\n",
       "      <th>Action detail</th>\n",
       "      <th>Queen status</th>\n",
       "      <th>Is alive</th>\n",
       "      <th>Report notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>3627</td>\n",
       "      <td>hive status</td>\n",
       "      <td>queenright</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>nucs All qr. added second and queen excluders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>3627</td>\n",
       "      <td>hive grading</td>\n",
       "      <td>medium</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>nucs All qr. added second and queen excluders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-20</th>\n",
       "      <td>3627</td>\n",
       "      <td>hive grading</td>\n",
       "      <td>weak</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-04</th>\n",
       "      <td>3627</td>\n",
       "      <td>hive grading</td>\n",
       "      <td>medium</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>7fob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-11</th>\n",
       "      <td>3627</td>\n",
       "      <td>hive grading</td>\n",
       "      <td>medium</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>7 frames of brood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>3629</td>\n",
       "      <td>varroa</td>\n",
       "      <td>2</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>3629</td>\n",
       "      <td>treatment</td>\n",
       "      <td>mite away</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>3629</td>\n",
       "      <td>frames of bees</td>\n",
       "      <td>5</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>Lots of dead bees under bee escape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>3629</td>\n",
       "      <td>feeding</td>\n",
       "      <td>sugar</td>\n",
       "      <td>queenright</td>\n",
       "      <td>1</td>\n",
       "      <td>603 got minimal syrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>3629</td>\n",
       "      <td>hive status</td>\n",
       "      <td>deadout</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tag number        Category Action detail Queen status  Is alive  \\\n",
       "Date                                                                          \n",
       "2022-06-02        3627     hive status    queenright   queenright         1   \n",
       "2022-06-02        3627    hive grading        medium   queenright         1   \n",
       "2022-06-20        3627    hive grading          weak   queenright         1   \n",
       "2022-07-04        3627    hive grading        medium   queenright         1   \n",
       "2022-07-11        3627    hive grading        medium   queenright         1   \n",
       "...                ...             ...           ...          ...       ...   \n",
       "2022-09-01        3629          varroa             2   queenright         1   \n",
       "2022-09-01        3629       treatment     mite away   queenright         1   \n",
       "2022-09-07        3629  frames of bees             5   queenright         1   \n",
       "2022-09-07        3629         feeding         sugar   queenright         1   \n",
       "2022-09-21        3629     hive status       deadout          NaN         0   \n",
       "\n",
       "                                                 Report notes  \n",
       "Date                                                           \n",
       "2022-06-02  nucs All qr. added second and queen excluders ...  \n",
       "2022-06-02  nucs All qr. added second and queen excluders ...  \n",
       "2022-06-20                                                NaN  \n",
       "2022-07-04                                               7fob  \n",
       "2022-07-11                                  7 frames of brood  \n",
       "...                                                       ...  \n",
       "2022-09-01                                                NaN  \n",
       "2022-09-01                                                NaN  \n",
       "2022-09-07                 Lots of dead bees under bee escape  \n",
       "2022-09-07                              603 got minimal syrup  \n",
       "2022-09-21                                                NaN  \n",
       "\n",
       "[278 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022['Date'] = pd.to_datetime(data_2022['Date'], format=\"%Y-%m-%d %H:%M:%S.%f%z\", errors='coerce').dt.date\n",
    "data_2022 = data_2022.set_index('Date')\n",
    "data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687233a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_2022['Date'] = pd.to_datetime(data_2022['Date'], dayfirst=True).dt.date\n",
    "#data_2022 = data_2022.set_index('Date')\n",
    "#data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86e3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022 = data_2022[data_2022['Category'] == 'frames of bees']\n",
    "data_2022['Action detail'] = pd.to_numeric(data_2022['Action detail']) # conver the column from object to float\n",
    "data_2022['Action detail'] = data_2022['Action detail'].astype('f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80936af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022[\"fob\"] = data_2022[\"Action detail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f18d050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_2022.groupby(['Tag number'])\n",
    "dict_hives_2022 = {}\n",
    "for i in data_2022['Tag number'].unique():\n",
    "        dict_hives_2022[i] = grouped.get_group(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f7a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in  data_2022['Tag number'].unique():\n",
    "    idx = pd.date_range(dict_hives_2022[hive].index.min(), dict_hives_2022[hive].index.max() + timedelta (days=1), freq=\"15min\")\n",
    "    dict_hives_2022[hive] = dict_hives_2022[hive].reindex(idx)\n",
    "    dict_hives_2022[hive] = dict_hives_2022[hive].interpolate(method=\"linear\")#interpolate(method=\"ffill\")\n",
    "    dict_hives_2022[hive]['fob'] = dict_hives_2022[hive]['fob']#.round(0).astype('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe30cc4",
   "metadata": {},
   "source": [
    "# MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4dfb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "\n",
    "win = 1600\n",
    "shift = 800\n",
    "\n",
    "df = feature_extraction(feature='mfccs', sample_rate= 16000, n_fft = win,\n",
    "                        hop_length = shift, dict_hives=dict_hives, hives=hives, year=2021, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2021_df_mfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_filter_26.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_extraction(feature='mfccs', sample_rate= 16000, n_fft = win,\n",
    "                        hop_length = shift, dict_hives=dict_hives_2022, hives=hives, year=2022, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2022_df_mfccs_win_\" + str(win) +'_shift_' + str(shift) +\n",
    "             \"_n_filter_26.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='mfccs', sample_rate= 16000, n_fft = win,\n",
    "                            hop_length = shift, dict_hives=dict_hives, hives=[hive], year=2021,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2021_df_ss_amp_mfccs_win_\" + str(win) +'_shift_' + \n",
    "                 str(shift) +'_' + str(hive) + \"_n_mels_26.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='mfccs', sample_rate= 16000, n_fft = win,\n",
    "                            hop_length = shift, dict_hives=dict_hives_2022, hives=[hive], year=2022,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2022_df_ss_amp_mfccs_win_\" + str(win) +'_shift_' + str(shift) +'_' + str(hive) + \"_n_mels_26.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0351e7",
   "metadata": {},
   "source": [
    "# LFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "win=1600\n",
    "shift=800\n",
    "\n",
    "df = feature_extraction(feature='lfccs', sample_rate= 16000, n_fft = win,\n",
    "                        hop_length = shift, dict_hives=dict_hives, hives=hives, year=2021, enhancement=False)\n",
    "df.to_pickle(\"../data//features/2021_df_lfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_filter_26.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf43d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_extraction(feature='lfccs', sample_rate= 16000, n_fft = win, hop_length = shift, dict_hives=dict_hives_2022, hives=hives, year=2022, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2022_df_lfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_filter_26.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63733801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='lfccs', sample_rate= 16000, n_fft = win,\n",
    "                            hop_length = shift, dict_hives=dict_hives, hives=[hive], year=2021,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2021_df_ss_amp_lfccs_win_\" + str(win) +'_shift_' +\n",
    "                 str(shift) +'_' + str(hive) + \"_n_mels_26.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13dabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='lfccs', sample_rate= 16000, n_fft = win,\n",
    "                            hop_length = shift, dict_hives=dict_hives_2022, hives=[hive], year=2022,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2022_df_ss_amp_lfccs_win_\" + str(win) +'_shift_' +\n",
    "                 str(shift) +'_' + str(hive) + \"_n_mels_26.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace8805",
   "metadata": {},
   "source": [
    "# Spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "\n",
    "\n",
    "df = feature_extraction(feature='spectral_shape_descriptors', sample_rate= 16000, n_fft = 1600,\n",
    "                        hop_length = 800, dict_hives=dict_hives, hives=hives, year=2021, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2021_df_spectral_nine_features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_extraction(feature='spectral_shape_descriptors', sample_rate= 16000, n_fft = 1600,\n",
    "                        hop_length = 800, dict_hives=dict_hives_2022, hives=hives, year=2022, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2022_df_spectral_nine_features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='spectral_shape_descriptors', sample_rate= 16000, n_fft = 1600,\n",
    "                            hop_length = 800, dict_hives=dict_hives, hives=[hive], year=2021,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2021_df_ss_amp_spectral_nine_features_\" + str(hive) + \".pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='spectral_shape_descriptors', sample_rate= 16000, n_fft = 1600,\n",
    "                            hop_length = 800, dict_hives=dict_hives_2022, hives=[hive], year=2022,  enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2022_df_ss_amp_spectral_nine_features_\" + str(hive) + \".pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bff77",
   "metadata": {},
   "source": [
    "# Hand crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8737679",
   "metadata": {},
   "outputs": [],
   "source": [
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "\n",
    "df = feature_extraction(feature='nectar_hand_crafted', sample_rate= 15625, n_fft=512,\n",
    "                        hop_length=512, dict_hives=dict_hives, hives=hives, year=2021, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2021_df_nectar_features.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_extraction(feature='nectar_hand_crafted', sample_rate= 15625, n_fft=512,\n",
    "                        hop_length=512, dict_hives=dict_hives_2022, hives=hives, year=2022, enhancement=False)\n",
    "df.to_pickle(\"../data/features/2022_df_nectar_features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='nectar_hand_crafted', sample_rate= 15625, n_fft=512,\n",
    "                            hop_length=512, dict_hives=dict_hives, hives=[hive], year=2021, enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2021_df_ss_amp_hand_crafted_\" + str(hive) + \".pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ef835",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hive in hives: \n",
    "    df = feature_extraction(feature='nectar_hand_crafted', sample_rate= 15625, n_fft=512,\n",
    "                            hop_length=512, dict_hives=dict_hives_2022, hives=[hive], year=2022, enhancement=True)\n",
    "    df.to_pickle(\"../data/features/2022_df_ss_amp_hand_crafted_\" + str(hive) + \".pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c57f84",
   "metadata": {},
   "source": [
    "# Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 1600\n",
    "shift= 800\n",
    "\n",
    "mfccs_2021 = pd.read_pickle(\"../data/features/2021_df_mfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_mels_26.pkl\")\n",
    "mfccs_2022 = pd.read_pickle(\"../data/features/2022_df_mfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_mels_26.pkl\")\n",
    "\n",
    "\n",
    "mfccs_2021['date'] = pd.to_datetime(mfccs_2021['date'], dayfirst=True)\n",
    "mfccs_2021 = mfccs_2021.set_index(mfccs_2021['date'])\n",
    "mfccs_2021 = mfccs_2021.drop(['date'], axis=1)\n",
    "\n",
    "mfccs_2022['date'] = pd.to_datetime(mfccs_2022['date'], dayfirst=True)\n",
    "mfccs_2022 = mfccs_2022.set_index(mfccs_2022['date'])\n",
    "mfccs_2022 = mfccs_2022.drop(['date'], axis=1)\n",
    "\n",
    "mfccs_2022['tag'] = mfccs_2022['tag']+ 10\n",
    "mfccs = pd.concat([mfccs_2021, mfccs_2022])\n",
    "mfccs.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "lfccs_2021 = pd.read_pickle(\"../data/features/2021_df_lfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_filter_26.pkl\")\n",
    "lfccs_2022 = pd.read_pickle(\"../data/features/2022_df_lfccs_win_\" + str(win) +'_shift_' + str(shift) + \"_n_filter_26.pkl\")\n",
    "\n",
    "\n",
    "lfccs_2021['date'] = pd.to_datetime(lfccs_2021['date'], dayfirst=True)\n",
    "lfccs_2021 = lfccs_2021.set_index(lfccs_2021['date'])\n",
    "lfccs_2021 = lfccs_2021.drop(['date'], axis=1)\n",
    "\n",
    "lfccs_2022['date'] = pd.to_datetime(lfccs_2022['date'], dayfirst=True)\n",
    "lfccs_2022 = lfccs_2022.set_index(lfccs_2022['date'])\n",
    "lfccs_2022 = lfccs_2022.drop(['date'], axis=1)\n",
    "\n",
    "lfccs_2022['tag'] = lfccs_2022['tag']+ 10\n",
    "lfccs = pd.concat([lfccs_2021, lfccs_2022])\n",
    "lfccs.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "spectral_2021 = pd.read_pickle(\"../data/features/2021_df_spectral_nine_features.pkl\")\n",
    "spectral_2022 = pd.read_pickle(\"../data/features/2022_df_spectral_nine_features.pkl\")\n",
    "\n",
    "spectral_2021['date'] = pd.to_datetime(spectral_2021['date'], dayfirst=True)\n",
    "spectral_2021 = spectral_2021.set_index(spectral_2021['date'])\n",
    "spectral_2021 = spectral_2021.drop(['date'], axis=1)\n",
    "\n",
    "spectral_2022['date'] = pd.to_datetime(spectral_2022['date'], dayfirst=True)\n",
    "spectral_2022 = spectral_2022.set_index(spectral_2022['date'])\n",
    "spectral_2022 = spectral_2022.drop(['date'], axis=1)\n",
    "\n",
    "spectral_2022['tag'] = spectral_2022['tag']+ 10\n",
    "spectral = pd.concat([spectral_2021, spectral_2022])\n",
    "spectral.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "hand_crafted_2021 = pd.read_pickle(\"../data/features/2021_df_hand_crafted_features.pkl\")\n",
    "hand_crafted_2022 = pd.read_pickle(\"../data/features/2022_df_hand_crafted_features.pkl\")\n",
    "\n",
    "hand_crafted_2021['date'] = pd.to_datetime(hand_crafted_2021['date'], dayfirst=True)\n",
    "hand_crafted_2021 = hand_crafted_2021.set_index(hand_crafted_2021['date'])\n",
    "hand_crafted_2021 = hand_crafted_2021.drop(['date'], axis=1)\n",
    "\n",
    "hand_crafted_2022['date'] = pd.to_datetime(hand_crafted_2022['date'], dayfirst=True)\n",
    "hand_crafted_2022 = hand_crafted_2022.set_index(hand_crafted_2022['date'])\n",
    "hand_crafted_2022 = hand_crafted_2022.drop(['date'], axis=1)\n",
    "\n",
    "hand_crafted_2022['tag'] = hand_crafted_2022['tag']+ 10\n",
    "hand_crafted = pd.concat([hand_crafted_2021, hand_crafted_2022])\n",
    "hand_crafted.drop(columns=['raw_audio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa59a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 1600\n",
    "shift= 800\n",
    "\n",
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "\n",
    "    \n",
    "mfccs_ss_2021=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2021}_df_ss_amp_mfccs_win_{win}_shift_{shift}_{hive}_n_mels_26.pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "mfccs_ss_2021['date'] = pd.to_datetime(mfccs_ss_2021['date'], dayfirst=True)\n",
    "mfccs_ss_2021 = mfccs_ss_2021.set_index(mfccs_ss_2021['date'])\n",
    "mfccs_ss_2021 = mfccs_ss_2021.drop(['date'], axis=1)\n",
    "\n",
    "mfccs_ss_2022=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2022}_df_ss_amp_mfccs_win_{win}_shift_{shift}_{hive}_n_mels_26.pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "mfccs_ss_2022['date'] = pd.to_datetime(mfccs_ss_2022['date'], dayfirst=True)\n",
    "mfccs_ss_2022 = mfccs_ss_2022.set_index(mfccs_ss_2022['date'])\n",
    "mfccs_ss_2022 = mfccs_ss_2022.drop(['date'], axis=1)\n",
    "\n",
    "mfccs_ss_2022['tag'] = mfccs_ss_2022['tag']+ 10\n",
    "mfccs_ss = pd.concat([mfccs_ss_2021, mfccs_ss_2022])\n",
    "mfccs_ss.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "lfccs_ss_2021=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2021}_df_ss_amp_lfccs_win_{win}_shift_{shift}_{hive}_n_mels_26.pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "lfccs_ss_2021['date'] = pd.to_datetime(lfccs_ss_2021['date'], dayfirst=True)\n",
    "lfccs_ss_2021 = lfccs_ss_2021.set_index(lfccs_ss_2021['date'])\n",
    "lfccs_ss_2021 = lfccs_ss_2021.drop(['date'], axis=1)\n",
    "\n",
    "lfccs_ss_2022=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2022}_df_ss_amp_lfccs_win_{win}_shift_{shift}_{hive}_n_mels_26.pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "lfccs_ss_2022['date'] = pd.to_datetime(lfccs_ss_2022['date'], dayfirst=True)\n",
    "lfccs_ss_2022 = lfccs_ss_2022.set_index(lfccs_ss_2022['date'])\n",
    "lfccs_ss_2022 = lfccs_ss_2022.drop(['date'], axis=1)\n",
    "\n",
    "lfccs_ss_2022['tag'] = lfccs_ss_2022['tag']+ 10\n",
    "lfccs_ss = pd.concat([lfccs_ss_2021, lfccs_ss_2022])\n",
    "lfccs_ss.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "spectral_ss_2021=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2021}_df_ss_amp_spectral_nine_features_\" + str(hive) + \".pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "spectral_ss_2021['date'] = pd.to_datetime(spectral_ss_2021['date'], dayfirst=True)\n",
    "spectral_ss_2021 = spectral_ss_2021.set_index(spectral_ss_2021['date'])\n",
    "spectral_ss_2021 = spectral_ss_2021.drop(['date'], axis=1)\n",
    "\n",
    "spectral_ss_2022=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2022}_df_ss_amp_spectral_nine_features_\" + str(hive) + \".pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "spectral_ss_2022['date'] = pd.to_datetime(spectral_ss_2022['date'], dayfirst=True)\n",
    "spectral_ss_2022 = spectral_ss_2022.set_index(spectral_ss_2022['date'])\n",
    "spectral_ss_2022 = spectral_ss_2022.drop(['date'], axis=1)\n",
    "\n",
    "spectral_ss_2021.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "spectral_ss_2022.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "spectral_ss_2021 = spectral_ss_2021.dropna(axis='columns')\n",
    "\n",
    "spectral_ss_2022 = spectral_ss_2022.dropna(axis='columns')\n",
    "\n",
    "spectral_ss_2022['tag'] = spectral_ss_2022['tag']+ 10\n",
    "spectral_ss = pd.concat([spectral_ss_2021, spectral_ss_2022])\n",
    "spectral_ss.drop(columns=['raw_audio'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "hives = [6, 3627, 3628, 3629, 3631, 3640, 3690, 3691, 3692, 3693]\n",
    "\n",
    "    \n",
    "hand_crafted_ss_2021=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2021}_df_ss_amp_hand_crafted_\" + str(hive) + \".pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "hand_crafted_ss_2021['date'] = pd.to_datetime(hand_crafted_ss_2021['date'], dayfirst=True)\n",
    "hand_crafted_ss_2021 = hand_crafted_ss_2021.set_index(hand_crafted_ss_2021['date'])\n",
    "hand_crafted_ss_2021 = hand_crafted_ss_2021.drop(['date'], axis=1)\n",
    "\n",
    "hand_crafted_ss_2022=pd.concat(\n",
    "        [pd.read_pickle(f\"../data/features/{2022}_df_ss_amp_hand_crafted_\" + str(hive) + \".pkl\") \n",
    "         for hive in hives],\n",
    "        ignore_index=True)\n",
    "\n",
    "\n",
    "hand_crafted_ss_2022['date'] = pd.to_datetime(hand_crafted_ss_2022['date'], dayfirst=True)\n",
    "hand_crafted_ss_2022 = hand_crafted_ss_2022.set_index(hand_crafted_ss_2022['date'])\n",
    "hand_crafted_ss_2022 = hand_crafted_ss_2022.drop(['date'], axis=1)\n",
    "\n",
    "\n",
    "hand_crafted_ss_2022['tag'] = hand_crafted_ss_2022['tag']+ 10\n",
    "hand_crafted_ss = pd.concat([hand_crafted_ss_2021, hand_crafted_ss_2022])\n",
    "\n",
    "hand_crafted_ss.drop(columns=['raw_audio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ac9a9",
   "metadata": {},
   "source": [
    "# Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2821e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'mfcc' # 'mfcc', lfcc', 'spectral', \n",
    "\n",
    "feature_data = mfcc    # mfccs, lfccs, spectral, hand_crafted\n",
    "method = 'shap' #'mrmr' 'shap'\n",
    "split = 'random' # 'independent'\n",
    "n_splits = 5\n",
    "model='random forest'\n",
    "preprocessing = 'off'\n",
    "selected_columns = feature_data.columns[2:]\n",
    "\n",
    "feature_data_15, feature_data_rest = train_test_split(feature_data, test_size=0.85, random_state=42)\n",
    "\n",
    "features_selection_cv(feature, feature_data_15, selected_columns, n_splits, method, split, model, preprocessing)\n",
    "read_and_plot_results(method, feature, split, preprocessing='off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66401324",
   "metadata": {},
   "source": [
    "# Run model on the best number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5f36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature = 'mfcc' # 'lfcc', 'spectral'\n",
    "\n",
    "feature_data = mfccs #lfcc, spectral\n",
    "method = 'shap' #'mrmr'\n",
    "split = 'random' # 'independent'\n",
    "n_splits = 5\n",
    "model = 'random forest'\n",
    "fobs = 'all'\n",
    "folds = '5folds' # '5folds'\n",
    "\n",
    "num_features = 12\n",
    "preprocessing = 'on'\n",
    "\n",
    "random_predictions = np.load(f\"random_regressor_mfcc_0_{folds}_{fobs}_{model}_shap_predictions_{split}_preprocessing_{preprocessing}.npy\", allow_pickle=True)\n",
    "\n",
    "feature_data_15, feature_data_rest = train_test_split(feature_data, test_size=0.85, random_state=42)\n",
    "\n",
    "\n",
    "ranking_filename = f\"{feature}_{method}_feature_ranking_{split}_preprocessing_off.csv\"\n",
    "ranking_df = pd.read_csv(ranking_filename)\n",
    "feature_ranking_idxs = ranking_df[\"Feature Index\"].values\n",
    "\n",
    "print(f\"Feature indices loaded: {feature_ranking_idxs}\")\n",
    "\n",
    "    \n",
    "selected_columns = feature_data.columns[2:][feature_ranking_idxs[:num_features]] # select the best number of features\n",
    "\n",
    "\n",
    "model_predictions, y_tests, _, _ =  random_split_cv(feature_data_rest, selected_columns, n_splits=n_splits, model=model)\n",
    "evaluate_model_performance(y_tests, random_predictions, model_predictions)\n",
    "\n",
    "\n",
    "np.save(f\"y_tests_{folds}_{fobs}_{split}_preprocessing_{preprocessing}.npy\", y_tests)\n",
    "np.save(f\"{feature}_{folds}_{fobs}_{model}_{method}_predictions_{split}_preprocessing_{preprocessing}.npy\", model_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aab94",
   "metadata": {},
   "source": [
    "# Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'mfccs' # 'mfcc', lfcc', 'spectral', 'hand_crafted'\n",
    "\n",
    "feature_data = mfccs    # mfccs, lfccs, spectral   \n",
    "method = 'shap' #'mrmr' 'shap'\n",
    "split = 'independent' # 'independent', 'random'\n",
    "n_splits = 5\n",
    "model='random forest'\n",
    "preprocessing = 'off'\n",
    "selected_columns = feature_data.columns[2:]\n",
    "\n",
    "list_hives_feature_selection = [3692, 3650, 3638, 3627]\n",
    "feature_data_15 = feature_data[feature_data['tag'].isin(list_hives_feature_selection)]\n",
    "feature_data_rest = feature_data[~feature_data['tag'].isin(list_hives_feature_selection)]\n",
    "\n",
    "features_selection_cv(feature, feature_data_15, selected_columns, n_splits, method, split, model, preprocessing)\n",
    "read_and_plot_results(method, feature, split, preprocessing='off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23157e10",
   "metadata": {},
   "source": [
    "# Run model on the best number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00525f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'mfccs' #'lfcc', 'spectral', 'mssd'\n",
    "feature_data = mfccs #lfcc, spectral, hand_crafted\n",
    "method = 'mrmr' #'mrmr'\n",
    "list_hives_feature_selection = [3692, 3650, 3638, 3627]\n",
    "\n",
    "feature_data_rest = feature_data[~feature_data['tag'].isin(list_hives_feature_selection)]\n",
    "\n",
    "split = 'independent' # 'independent'\n",
    "model = 'random forest'\n",
    "preprocessing = 'on'\n",
    "fobs = 'all'\n",
    "folds = '5folds' # '5folds'\n",
    "\n",
    "if folds=='loo':\n",
    "    n_outer_folds = feature_data_rest['tag'].nunique()\n",
    "else:\n",
    "    n_outer_folds = 5\n",
    "    \n",
    "num_features = 10\n",
    "    \n",
    "\n",
    "ranking_filename = f\"mfcc_{method}_feature_ranking_{split}_preprocessing_off.csv\"\n",
    "ranking_df = pd.read_csv(ranking_filename)\n",
    "feature_ranking_idxs = ranking_df[\"Feature Index\"].values\n",
    "\n",
    "print(f\"Feature indices loaded: {feature_ranking_idxs}\")\n",
    "\n",
    "selected_columns = feature_data.columns[2:][feature_ranking_idxs[:num_features]] # select the best number of features\n",
    "\n",
    "\n",
    "model_predictions, y_tests, _, _, hive_results = hive_independent_cv(feature_data_rest, selected_columns, model=model,\n",
    "                                                           n_outer_folds=n_outer_folds, n_inner_folds=5)\n",
    "\n",
    "np.save(f\"{feature}_{folds}_{fobs}_{model}_{method}_predictions_{split}_preprocessing_{preprocessing}.npy\", model_predictions)\n",
    "\n",
    "with open(f\"{feature}_{folds}_{fobs}_{model}_{method}_hive_results_{split}_preprocessing_{preprocessing}.pkl\", 'wb') as file:\n",
    "    pickle.dump(hive_results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_3_8",
   "language": "python",
   "name": "conda_env_3_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
